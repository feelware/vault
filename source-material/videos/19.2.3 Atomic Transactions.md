---
tags:
  - "#video-notes"
src-date: 2019-07-12
src-author:
  - MIT OpenCourseWare
src-link: https://youtu.be/776ZuSOo6hg
---
# 19.2.3 Atomic Transactions

## Withdrawal scenario

- Suppose a withdrawal operation composed of three instructions:
	- `LD(account, balance)` loads the current balance from `account` into `balance` 
	- `SUB(balance, amnt)` subtracts the amount to withdraw `amnt` from `balance`
	- `ST(account, balance)` stores the updated `balance` back into `account`
- Suppose two $50 withdrawals from the same account (which currently has $100) happening at the same time:
- If `P1` completes before `P2`, nothing special happens
```
P1:
	LD(acc, bal)       // bal = 100
	SUB(bal, 50)       // bal = bal - 50 = 50
	ST(acc, bal)       // account balance is now $50

P2:
	LD(acc, bal)       // bal = 50
	SUB(bal, 50)       // bal = bal - 50 = 0
	ST(acc, bal)       // account balance is now $0
```
- If `P2` starts and completes during the execution of `P1`, `P1` will end up calculating the new balance by subtracting from the outdated value of `bal`, leaving the account with $50 rather than $0
```
P1:
	LD(acc, bal)       // bal = 100

P2:
	LD(acc, bal)       // bal = 100
	SUB(bal, 50)       // bal = bal - 50 = 50
	ST(acc, bal)       // account balance is now $50

P1 (resumed):
	SUB(bal, 50)       // bal = bal - 50 = 50
	ST(acc, bal)       // account balance is now $50
```

## Moral of the story

- You need to be careful when updating shared data based on previous values.
- A process `P1` might retrieve the current value of `x` right before another process `P2` is done modifying `x`, leaving `P1` with an outdated copy to work with.
- We must ensure that no other process accesses shared data during the entire `load -> update -> store` sequence. We call this sequence the **critical section**.
- If one or many processes happen to reach the critical section while the current process is executing it, they have to **wait** until the current one exits the section. This is called **mutual exclusion** (mutex).
- A mutex can be implemented with semaphores.
	- A semaphore `lock` is initialized to one (**one** slot available)
	- A call to `wait(lock)` is placed right before the critical section, and a call to `signal(lock)` right after.
	- Whichever process happens to reach the critical section first will *acquire* `lock`. This will decrement `lock` to zero (**zero** slots available), making other processes *wait* in a queue.
	- As soon as the lock owner exits the critical section, the call to `signal` will increase `lock` back to one. The first process in the queue will then acquire the lock, decreasing it back to zero.
- This constraint guarantees that two or more executions of the critical section **cannot overlap**.
- They may run in any order.